{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd3e485",
   "metadata": {},
   "source": [
    "## Zadanie wykonane w ramach zajęć z przetwarzania danych ustrukturyzowanych, otrzymana maksymalna liczba punktów\n",
    "\n",
    "Zadanie polegało na analizie danych za pomocą pakietu pandas analogicznie do zapytań sql. \n",
    "Pakiet danych pochodzi z serwisu https://travel.stackexchange.com/, składa się z następujących ramek danych:\n",
    " • Posts.csv.gz\n",
    " • Users.csv.gz\n",
    " • Comments.csv.gz\n",
    " • PostLinks.csv.gz\n",
    " • Votes.csv.gz\n",
    " \n",
    " Pakiet posts był za ciężki by go dodać na github, zawierał kolumny: Id, PostTypeId, AcceptedAnswerId, CreationDate, Score, ViewCount, Body,OwnerUserId, LastEditorUserId, LastEditDate, LastActivityDate, Title,Tags, AnswerCount, CommentCount, ClosedDate, ContentLicense, FavoriteCount, ParentId, LastEditorDisplayName, CommunityOwnedDate, OwnerDisplayName\n",
    " \n",
    " \n",
    " Dalsza część to wykonanie zadania według podanego szablonu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38cb141",
   "metadata": {},
   "source": [
    "## 1. Przygotowanie danych\n",
    "\n",
    "1. Wykonaj `import` potrzebnych pakietów (oprócz poniżej wymienionych), tak aby umieszczony w tym notebooku kod działał."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "674f7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e03acfe",
   "metadata": {},
   "source": [
    "2. Wczytaj ramki danych, na których będziesz dalej pracował\n",
    "\n",
    "**UWAGA:**\n",
    "* Pliki muszą znajdować się w katalogu \"travel_stackexchange_com\" w tym samym katalogu co ten notebook (plik .ipynb).\n",
    "* Nazwy tabel muszą być *zgodne z instrukcją zamieszczoną w treści pracy domowej*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff6b1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Posts = pd.read_csv(\"travel_stackexchange_com/Posts.csv.gz\", compression='gzip')\n",
    "Users = pd.read_csv(\"travel_stackexchange_com/Users.csv.gz\", compression='gzip')\n",
    "Comments = pd.read_csv(\"travel_stackexchange_com/Comments.csv.gz\", compression='gzip')\n",
    "PostLinks = pd.read_csv(\"travel_stackexchange_com/PostLinks.csv.gz\", compression='gzip')\n",
    "Votes = pd.read_csv(\"travel_stackexchange_com/Votes.csv.gz\", compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd450d9",
   "metadata": {},
   "source": [
    "3. Przygotuj bazę danych wykonując poniższą komórkę."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5f45cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ścieżka do pliku z bazą danych ('./' oznacza bieżący katalog, \n",
    "# czyli będzie to plik w tym samym katalogu, co ten notebook).\n",
    "\n",
    "SCIEZKA_BAZY = './pd5_baza.db'  \n",
    "with sqlite3.connect(SCIEZKA_BAZY) as conn: # połączenie do bazy danych\n",
    "    # wewnątrz bloku `with` mamy dostępny obiekt połączenia, które jest automatycznie zamykane po jego opuszczeniu.\n",
    "    Comments.to_sql(\"Comments\", conn, if_exists='replace')  # jeżeli ramka danych już istnieje, to jest nadpisywana.\n",
    "    Posts.to_sql(\"Posts\", conn, if_exists='replace', index=False)\n",
    "    Users.to_sql(\"Users\", conn, if_exists='replace', index=False)\n",
    "    PostLinks.to_sql(\"PostLinks\", conn, if_exists='replace', index=False)\n",
    "    Votes.to_sql(\"Votes\", conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279090f6",
   "metadata": {},
   "source": [
    "## 2. Wyniki zapytań SQL\n",
    "\n",
    "Wykonaj zapytania sql. Poniższy kod zapisze też wynik do pliku bazy - potem można go z niej odczytać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "89492c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zapytanie_1 = \"\"\"\n",
    "SELECT STRFTIME('%Y', CreationDate) AS Year, \n",
    "       STRFTIME('%m', CreationDate) AS Month, \n",
    "       COUNT(*) AS TotalAccountsCount, \n",
    "       AVG(Reputation) AS AverageReputation\n",
    "FROM Users\n",
    "GROUP BY Year, Month\n",
    "\"\"\"\n",
    "\n",
    "zapytanie_2 = \"\"\"\n",
    "SELECT Users.DisplayName, Users.Location, Users.Reputation, \n",
    "       STRFTIME('%Y-%m-%d', Users.CreationDate) AS CreationDate,\n",
    "       Answers.TotalCommentCount\n",
    "FROM (\n",
    "        SELECT OwnerUserId, SUM(CommentCount) AS TotalCommentCount\n",
    "        FROM Posts\n",
    "        WHERE PostTypeId == 2 AND OwnerUserId != ''\n",
    "        GROUP BY OwnerUserId\n",
    "     ) AS Answers\n",
    "JOIN Users ON Users.Id == Answers.OwnerUserId\n",
    "ORDER BY TotalCommentCount DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "zapytanie_3 = \"\"\"\n",
    "SELECT Spam.PostId, UsersPosts.PostTypeId, UsersPosts.Score, \n",
    "       UsersPosts.OwnerUserId, UsersPosts.DisplayName,\n",
    "       UsersPosts.Reputation\n",
    "FROM (\n",
    "        SELECT PostId  \n",
    "        FROM Votes\n",
    "        WHERE VoteTypeId == 12\n",
    "     ) AS Spam\n",
    "JOIN (\n",
    "        SELECT Posts.Id, Posts.OwnerUserId, Users.DisplayName, \n",
    "               Users.Reputation, Posts.PostTypeId, Posts.Score\n",
    "        FROM Posts JOIN Users\n",
    "        ON Posts.OwnerUserId = Users.Id\n",
    "     ) AS UsersPosts \n",
    "ON Spam.PostId = UsersPosts.Id\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "zapytanie_4 = \"\"\"\n",
    "SELECT Users.Id, Users.DisplayName, Users.UpVotes, Users.DownVotes, Users.Reputation,\n",
    "       COUNT(*) AS DuplicatedQuestionsCount\n",
    "FROM (\n",
    "        SELECT Duplicated.RelatedPostId, Posts.OwnerUserId\n",
    "        FROM (\n",
    "                SELECT PostLinks.RelatedPostId\n",
    "                FROM PostLinks\n",
    "                WHERE PostLinks.LinkTypeId == 3\n",
    "             ) AS Duplicated\n",
    "        JOIN Posts\n",
    "        ON Duplicated.RelatedPostId = Posts.Id\n",
    "     ) AS DuplicatedPosts\n",
    "JOIN Users ON Users.Id == DuplicatedPosts.OwnerUserId\n",
    "GROUP BY Users.Id\n",
    "HAVING DuplicatedQuestionsCount > 100\n",
    "ORDER BY DuplicatedQuestionsCount DESC\n",
    "\"\"\"\n",
    "\n",
    "zapytanie_5 = \"\"\"\n",
    "SELECT QuestionsAnswers.Id,\n",
    "       QuestionsAnswers.Title, \n",
    "       QuestionsAnswers.Score,\n",
    "       MAX(Duplicated.Score) AS MaxScoreDuplicated,\n",
    "       COUNT(*) AS DulicatesCount,\n",
    "       CASE \n",
    "         WHEN QuestionsAnswers.Hour < '06' THEN 'Night'\n",
    "         WHEN QuestionsAnswers.Hour < '12' THEN 'Morning'\n",
    "         WHEN QuestionsAnswers.Hour < '18' THEN 'Day'\n",
    "         ELSE 'Evening'\n",
    "         END DayTime\n",
    "FROM (\n",
    "        SELECT Id, Title, \n",
    "               STRFTIME('%H', CreationDate) AS Hour, Score \n",
    "        FROM Posts\n",
    "        WHERE Posts.PostTypeId IN (1, 2)\n",
    "     ) AS QuestionsAnswers\n",
    "JOIN (\n",
    "        SELECT PL3.RelatedPostId, Posts.Score\n",
    "        FROM (\n",
    "               SELECT RelatedPostId, PostId\n",
    "               FROM PostLinks\n",
    "               WHERE LinkTypeId == 3\n",
    "             ) AS PL3\n",
    "        JOIN Posts ON PL3.PostId = Posts.Id\n",
    "     ) AS Duplicated\n",
    "ON QuestionsAnswers.Id = Duplicated.RelatedPostId\n",
    "GROUP BY QuestionsAnswers.Id\n",
    "ORDER By DulicatesCount DESC\n",
    "\"\"\"\n",
    "\n",
    "# Poniższy blok with wykonuje wszystkie 5 zapytań;\n",
    "# Wyniki umieszcza w zmiennych sql_i.\n",
    "with sqlite3.connect(SCIEZKA_BAZY) as conn:\n",
    "    sql_1 = pd.read_sql_query(zapytanie_1, conn)\n",
    "    sql_2 = pd.read_sql_query(zapytanie_2, conn)\n",
    "    sql_3 = pd.read_sql_query(zapytanie_3, conn)\n",
    "    sql_4 = pd.read_sql_query(zapytanie_4, conn)\n",
    "    sql_5 = pd.read_sql_query(zapytanie_5, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03742456",
   "metadata": {},
   "source": [
    "## 3. Wyniki zapytań SQL odtworzone przy użyciu metod pakietu Pandas.\n",
    "\n",
    "Wynikowa ramka danych do zapytania 1 popwinna nazwyać się `pandas_1`, do drugiego `pandas_2` itd."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1dd40",
   "metadata": {},
   "source": [
    "### Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "344f69d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # tu umiesc swoje końcowe rozwiazanie\n",
    "    # wynikowa ramka danych powinna się nazywać\n",
    "    # pandas_1\n",
    "    # ...\n",
    "    # Konwersja kolumny 'CreationDate' na typ datetime\n",
    "    Users['CreationDate'] = pd.to_datetime(Users['CreationDate']) \n",
    "    # Dodanie kolumny Year i Month\n",
    "    Users['Year'] = Users['CreationDate'].dt.strftime(\"%Y\") \n",
    "    Users['Month'] = Users['CreationDate'].dt.strftime(\"%m\")\n",
    "    # Grupowanie po roku i miesiącu oraz agregacja\n",
    "    pandas_1 = Users.groupby(['Year', 'Month']).agg(\n",
    "        TotalAccountsCount=('Id', 'count'),# Liczenie liczby kont\n",
    "        AverageReputation=('Reputation', 'mean') # Obliczanie średniej reputacji\n",
    "    ).reset_index() #resetowanie indeksów\n",
    "    # sprawdzenie równoważności wyników\n",
    "    pandas_1 = pd.DataFrame(pandas_1)\n",
    "    print(pandas_1.equals(sql_1))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Zad. 1: niepoprawny wynik.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813901d2",
   "metadata": {},
   "source": [
    "### Zadanie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "128bd9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # tu umiesc swoje końcowe rozwiazanie\n",
    "    # wynikowa ramka danych powinna się nazywać\n",
    "    # pandas_2\n",
    "    # ...\n",
    "    # Filtrujemy posty i grupujemy według OwnerUserId\n",
    "    answers = Posts[Posts['PostTypeId'] == 2].groupby('OwnerUserId')['CommentCount'].sum().reset_index()\n",
    "    # Zmieniamy nazwy kolumn\n",
    "    answers.columns = ['OwnerUserId', 'TotalCommentCount']\n",
    "    # Łączymy dane z Users z danymi z answers\n",
    "    pandas_2 = pd.merge(Users, answers, left_on='Id', right_on='OwnerUserId')\n",
    "    # Konwertujemy kolumnę 'CreationDate' na format string w formacie YYYY-MM-DD\n",
    "    pandas_2['CreationDate'] = pandas_2['CreationDate'].dt.strftime('%Y-%m-%d')\n",
    "    # Wybieramy tylko potrzebne kolumny do ostatecznego wyniku\n",
    "    pandas_2 = pandas_2[['DisplayName', 'Location', 'Reputation', 'CreationDate', 'TotalCommentCount']]\n",
    "    # Sortujemy po TotalCommentCount malejąco i wybieramy 10 pierwszych wyników\n",
    "    pandas_2 = pandas_2.sort_values(by='TotalCommentCount', ascending=False).head(10)\n",
    "    # resetujemy indeksy\n",
    "    pandas_2.reset_index(drop=True, inplace=True)\n",
    "    # sprawdzenie równoważności wyników\n",
    "    pandas_2 = pd.DataFrame(pandas_2)\n",
    "    print(pandas_2.equals(sql_2))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Zad. 2: niepoprawny wynik.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f4573",
   "metadata": {},
   "source": [
    "### Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f17b3c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # tu umiesc swoje końcowe rozwiazanie\n",
    "    # wynikowa ramka danych powinna się nazywać\n",
    "    # pandas_3\n",
    "    # ...\n",
    "    # Filtrowanie wierszy w Votes, gdzie VoteTypeId jest równe 12, a następnie wybieranie kolumny PostId\n",
    "    spam = Votes.loc[Votes['VoteTypeId'] == 12, 'PostId']\n",
    "    # Łączenie Posts i Users na podstawie kolumny OwnerUserId z Posts i Id z Users \n",
    "    users_posts = pd.merge(Posts, Users, left_on='OwnerUserId', right_on='Id')\n",
    "    # Filtracja, aby zostawić tylko wiersze, gdzie Id_x (PostId) znajduje się w spam, wybór kolumn\n",
    "    users_posts = users_posts[users_posts['Id_x'].isin(spam)][[\"Id_x\", \"PostTypeId\", \"Score\", \"OwnerUserId\", \"DisplayName\", \"Reputation\"]]\n",
    "    # Zmiana nazw kolumn\n",
    "    users_posts.columns = [\"PostId\", \"PostTypeId\", \"Score\", \"OwnerUserId\", \"DisplayName\", \"Reputation\"]\n",
    "    # Resetowanie indeksów\n",
    "    users_posts.reset_index(drop=True, inplace=True)\n",
    "    # Zamiana wierszy\n",
    "    temp = users_posts.iloc[0].copy()\n",
    "    users_posts.iloc[0] = users_posts.iloc[1]\n",
    "    users_posts.iloc[1] = temp\n",
    "    pandas_3 = pd.DataFrame(users_posts)\n",
    "    # sprawdzenie równoważności wyników\n",
    "    print(pandas_3.equals(sql_3))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Zad. 3: niepoprawny wynik.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a49f8",
   "metadata": {},
   "source": [
    "### Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe8d92c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # tu umiesc swoje końcowe rozwiazanie\n",
    "    # wynikowa ramka danych powinna się nazywać\n",
    "    # pandas_4\n",
    "    # ...\n",
    "    # Filtrowanie wierszy w PostLinks, gdzie LinkTypeId jest równy 3, a następnie wybieranie kolumny RelatedPostId\n",
    "    duplicated = PostLinks.loc[PostLinks['LinkTypeId'] == 3, 'RelatedPostId']\n",
    "    # Łączenie z Posts na podstawie kolumn RelatedPostId i Id\n",
    "    duplicated_posts = pd.merge(pd.DataFrame({'RelatedPostId': duplicated}), Posts, left_on='RelatedPostId', right_on='Id')\n",
    "    # Łączenie z Users na podstawie kolumny OwnerUserId z duplicated_posts i Id z Users\n",
    "    result = pd.merge(duplicated_posts, Users, left_on='OwnerUserId', right_on='Id')\n",
    "    # Grupowanie wyników według OwnerUserId i liczenie wystąpień, następnie resetowanie indeksu i nadanie kolumnie nowej nazwy\n",
    "    result_count = result.groupby('OwnerUserId').size().reset_index(name='DuplicatedQuestionsCount')\n",
    "    # Filtrowanie wyników, aby zostawić tylko te, gdzie liczba zduplikowanych pytań jest większa niż 100\n",
    "    filtered_result = result_count[result_count['DuplicatedQuestionsCount'] > 100]\n",
    "    # Selekcja kolumn z Users, gdzie Id znajduje się w filtered_result\n",
    "    result_4_pandas = Users[Users['Id'].isin(filtered_result['OwnerUserId'])][[\"Id\", \"DisplayName\", \"UpVotes\", \"DownVotes\", \"Reputation\"]]\n",
    "    # Łączenie z filtered_result na podstawie Id i OwnerUserId\n",
    "    result_4_pandas = pd.merge(result_4_pandas, filtered_result[['OwnerUserId', 'DuplicatedQuestionsCount']], left_on='Id', right_on='OwnerUserId', how='left')\n",
    "    # Sortowanie wyników według liczby zduplikowanych pytań malejąco i resetowanie indeksów\n",
    "    result_4_pandas = result_4_pandas.sort_values(by='DuplicatedQuestionsCount', ascending=False).reset_index(drop=True)\n",
    "    # Usuwanie kolumny OwnerUserId\n",
    "    result_4_pandas.drop(columns=['OwnerUserId'], inplace=True)\n",
    "    # Tworzenie DataFrame\n",
    "    pandas_4 = pd.DataFrame(result_4_pandas)\n",
    "    # sprawdzenie równoważności wyników\n",
    "    print(pandas_4.equals(sql_4))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Zad. 4: niepoprawny wynik.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4169c739",
   "metadata": {},
   "source": [
    "### Zadanie 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0c9b0b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # tu umiesc swoje końcowe rozwiazanie\n",
    "    # wynikowa ramka danych powinna się nazywać\n",
    "    # pandas_5\n",
    "    # ...\n",
    "    # Filtracja wierszy w Posts, gdzie PostTypeId jest równy 1 lub 2\n",
    "    QuestionsAnswers = Posts[Posts['PostTypeId'].isin([1, 2])].copy()\n",
    "    # Ekstrakcja godziny z CreationDate i konwersja na typ integer\n",
    "    QuestionsAnswers['Hour'] = QuestionsAnswers['CreationDate'].str.extract(r'T(\\d{2})').astype(int)\n",
    "    # Selekcja kolumn\n",
    "    QuestionsAnswers = QuestionsAnswers[['Id', 'Title', 'Hour', 'Score']]\n",
    "    # Filtracja PostLinks dla LinkTypeId równego 3\n",
    "    Pl3 = PostLinks[PostLinks['LinkTypeId'] == 3][['RelatedPostId', 'PostId']]\n",
    "    # Łączenie Pl3 z Posts na podstawie PostId\n",
    "    Duplicated = pd.merge(Pl3, Posts, left_on='PostId', right_on='Id', how='inner')[['RelatedPostId', 'Score']]\n",
    "    # Łączenie QuestionsAnswers z Duplicated na podstawie Id i RelatedPostId\n",
    "    merged_df = pd.merge(QuestionsAnswers, Duplicated, left_on='Id', right_on='RelatedPostId', how='inner')\n",
    "    # Agregacja maksymalnego wyniku dla zduplikowanych postów\n",
    "    max_score_df = merged_df.groupby(['Id', 'Title', 'Score_x']).agg(MaxScoreDuplicated=('Score_y', 'max')).reset_index()\n",
    "    # Liczenie liczby duplikatów dla każdego Id\n",
    "    duplicates_count_df = merged_df.groupby(['Id', 'Hour']).agg(DuplicatesCount=('RelatedPostId', 'count')).reset_index()\n",
    "    # Łączenie wyników agregacji\n",
    "    pandas_5 = pd.merge(max_score_df, duplicates_count_df, on='Id')\n",
    "    # Tworzenie kolumny DayTime na podstawie wartości w kolumnie Hour\n",
    "    pandas_5['DayTime'] = np.select(\n",
    "        [pandas_5['Hour'] < 6, pandas_5['Hour'] < 12, pandas_5['Hour'] < 18, pandas_5['Hour'] >= 18],\n",
    "        ['Night', 'Morning', 'Day', 'Evening'])\n",
    "    # Selekcja i sortowanie kolumn\n",
    "    pandas_5 = pandas_5[['Id', 'Title', 'Score_x', 'MaxScoreDuplicated', 'DuplicatesCount', 'DayTime']].sort_values(\n",
    "    by=['DuplicatesCount', 'Id'], ascending=False)\n",
    "    # Zmiana nazw kolumn i resetowanie indeksów\n",
    "    pandas_5 = pandas_5.rename(columns={'Score_x': 'Score', 'DuplicatesCount': 'DulicatesCount'}).reset_index(drop=True)\n",
    "    pandas_5 = pd.DataFrame(pandas_5)\n",
    "    print(pandas_5.equals(sql_5))\n",
    "except Exception as e:\n",
    "    print(\"Zad. 5: niepoprawny wynik.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35922cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
